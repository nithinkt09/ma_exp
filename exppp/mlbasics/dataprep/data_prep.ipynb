{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nindependent variables: inputs, predictors, or features that are used to explain or influence the outcomes \\ndependent variables: responses or outcomes influenced by changes in independent variables\\n\\ntraining set: data that is given or used to train and from which a model learns and predicts or figures out relationships between inputs and outputs\\ntest set: isolated from training set that could have unseen and real world data to evaluate model's performance\\n\\nfeature scaling: a method to standardized independent variables that adjusts the range of data features so that all features are equally proportionally\\n\""
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "independent variables: inputs, predictors, or features that are used to explain or influence the outcomes \n",
    "dependent variables: responses or outcomes influenced by changes in independent variables\n",
    "\n",
    "training set: data that is given or used to train and from which a model learns and predicts or figures out relationships between inputs and outputs\n",
    "test set: isolated from training set that could have unseen and real world data to evaluate model's performance\n",
    "\n",
    "feature scaling: a method to standardized independent variables that adjusts the range of data features so that all features are equally proportionally\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmin-max normalization: transform data so that every feature value falls into desired range (commonly being [0, 1])\\n\\nit could be mapped via a function where f(x) if x is minimum is mapped to 0 and if it is max it is mapped to 1\\n\\nf(x_min) = a * x_min + b = 0 => b = -a * x_min\\nf(x_max) = a * x_max + b = 1 => substituting b with -a * x_min => 1  = a (x_max - x_min) = 1\\na = 1 / (x_max - x_min)\\nf(x) = (1/(x_max - x_min)) * x - x_min/ (x_max - x_min) = (x - x_min )/ (x_max - x_min)\\n'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "min-max normalization: transform data so that every feature value falls into desired range (commonly being [0, 1])\n",
    "\n",
    "it could be mapped via a function where f(x) if x is minimum is mapped to 0 and if it is max it is mapped to 1\n",
    "\n",
    "f(x_min) = a * x_min + b = 0 => b = -a * x_min\n",
    "f(x_max) = a * x_max + b = 1 => substituting b with -a * x_min => 1  = a (x_max - x_min) = 1\n",
    "a = 1 / (x_max - x_min)\n",
    "f(x) = (1/(x_max - x_min)) * x - x_min/ (x_max - x_min) = (x - x_min )/ (x_max - x_min)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Country   Age   Salary\n",
      "0   France  44.0  72000.0\n",
      "1    Spain  27.0  48000.0\n",
      "2  Germany  30.0  54000.0\n",
      "3    Spain  38.0  61000.0\n",
      "4  Germany  40.0      NaN\n",
      "5   France  35.0  58000.0\n",
      "6    Spain   NaN  52000.0\n",
      "7   France  48.0  79000.0\n",
      "8  Germany  50.0  83000.0\n",
      "9   France  37.0  67000.0\n",
      "0     No\n",
      "1    Yes\n",
      "2     No\n",
      "3     No\n",
      "4    Yes\n",
      "5    Yes\n",
      "6     No\n",
      "7    Yes\n",
      "8     No\n",
      "9    Yes\n",
      "Name: Purchased, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data_set = pd.read_csv(\"../data/Data.csv\")\n",
    "\n",
    "# extract features from the dataset by locating the indexes of the columns and rows\n",
    "X = data_set.iloc[:, :-1]\n",
    "\n",
    "# extract the dependent values by locating the last index which is the output or dependent column\n",
    "y = data_set.iloc[:, -1]\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Country        Age        Salary\n",
      "0   France  44.000000  72000.000000\n",
      "1    Spain  27.000000  48000.000000\n",
      "2  Germany  30.000000  54000.000000\n",
      "3    Spain  38.000000  61000.000000\n",
      "4  Germany  40.000000  63777.777778\n",
      "5   France  35.000000  58000.000000\n",
      "6    Spain  38.777778  52000.000000\n",
      "7   France  48.000000  79000.000000\n",
      "8  Germany  50.000000  83000.000000\n",
      "9   France  37.000000  67000.000000\n",
      "0     No\n",
      "1    Yes\n",
      "2     No\n",
      "3     No\n",
      "4    Yes\n",
      "5    Yes\n",
      "6     No\n",
      "7    Yes\n",
      "8     No\n",
      "9    Yes\n",
      "Name: Purchased, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# imputer module of sklearn helps in handling missing data, of which SImpleImputer is a class which replaces missing values with some statistical value\n",
    "# missing_values: all the missing values that have the type of values specified \n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "# connect or apply the imputer to matrix of features and use the transform method to replace the missing values with respective strategy\n",
    "imputer.fit(X=X.iloc[:, 1:])\n",
    "\n",
    "# update the columns of X with new values with updated missing values\n",
    "X.iloc[:, 1:] = imputer.transform(X=X.iloc[:, 1:])\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+00 0.00000000e+00 0.00000000e+00 4.40000000e+01\n",
      "  7.20000000e+04]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 2.70000000e+01\n",
      "  4.80000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 3.00000000e+01\n",
      "  5.40000000e+04]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 3.80000000e+01\n",
      "  6.10000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 4.00000000e+01\n",
      "  6.37777778e+04]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 3.50000000e+01\n",
      "  5.80000000e+04]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 3.87777778e+01\n",
      "  5.20000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 4.80000000e+01\n",
      "  7.90000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 5.00000000e+01\n",
      "  8.30000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 3.70000000e+01\n",
      "  6.70000000e+04]]\n"
     ]
    }
   ],
   "source": [
    "# encoding categorical data or features: convert into n number of columns for n categorie with values where they have respectively 0 or 1 \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# object instance of Columntranfoomer class, remainder: passthrough: remainders are kept or preserved as they are\n",
    "ct = ColumnTransformer(\n",
    "    transformers = [('encoder', OneHotEncoder(), [0])], \n",
    "    remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the dependent variables of yes/no \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                  5.1               3.5                1.4               0.2\n",
      "1                  4.9               3.0                1.4               0.2\n",
      "2                  4.7               3.2                1.3               0.2\n",
      "3                  4.6               3.1                1.5               0.2\n",
      "4                  5.0               3.6                1.4               0.2\n",
      "..                 ...               ...                ...               ...\n",
      "145                6.7               3.0                5.2               2.3\n",
      "146                6.3               2.5                5.0               1.9\n",
      "147                6.5               3.0                5.2               2.0\n",
      "148                6.2               3.4                5.4               2.3\n",
      "149                5.9               3.0                5.1               1.8\n",
      "\n",
      "[150 rows x 4 columns]\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "145    2\n",
      "146    2\n",
      "147    2\n",
      "148    2\n",
      "149    2\n",
      "Name: target, Length: 150, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "# pd.Dataframe: pandas function that conevrts numpy array of iris data intoa pandas dataframe\n",
    "# iris.data: numpy array containing feature values of the dataset iris with each row corresponding to one iris flower and each column representing one of the four measurements\n",
    "# iris.feature_names: list of strings that represents each column that can be used by pandas as names of the columns\n",
    "iris_pd = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "# iris.target: a numpy array that has target values or labels for each of the iris sample corresponding to respective iris species\n",
    "# by adding a new column target that assigns specific information for each sample\n",
    "iris_pd['target'] = iris.target\n",
    "\n",
    "X_iris = iris_pd.iloc[:, :-1]\n",
    "y_iris = iris_pd.iloc[:, -1]\n",
    "\n",
    "print(X_iris)\n",
    "print(y_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into training and tests set\n",
    "# training set: data that is fed to develop the model\n",
    "# test set: to validate and correct the model based on the way the function is developed based on the trainig set and its output values\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling is operated on data to ensure that all the values or features have equal emphasis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\n",
    "X_test[:, 3:] = sc.fit_transform(X_test[:, 3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          1.          0.         -1.68580983 -1.05553882]\n",
      " [ 0.          1.          0.          1.53377393  1.64209282]\n",
      " [ 0.          0.          1.         -0.39797633 -0.40438635]\n",
      " [ 1.          0.          0.          0.5678988   0.61885324]\n",
      " [ 0.          1.          0.         -0.07601795 -0.14599252]\n",
      " [ 0.          0.          1.         -0.27277029 -1.24158238]\n",
      " [ 1.          0.          0.         -0.88091389 -0.68345169]\n",
      " [ 1.          0.          0.          1.21181555  1.2700057 ]]\n",
      "[[ 1.  0.  0.  1.  1.]\n",
      " [ 0.  0.  1. -1. -1.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlexp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
